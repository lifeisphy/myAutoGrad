# MyAutoGrad - C++ è‡ªåŠ¨å¾®åˆ†æ¡†æ¶

[![C++23](https://img.shields.io/badge/C%2B%2B-23-blue.svg)](https://en.wikipedia.org/wiki/C%2B%2B23)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Documentation](https://img.shields.io/badge/Documentation-latest-brightgreen.svg)](docs/)

ä¸€ä¸ªç”¨ C++ å®ç°çš„é«˜æ€§èƒ½è‡ªåŠ¨å¾®åˆ†æ¡†æ¶ï¼Œæ”¯æŒæ„å»ºå’Œè®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œã€‚è¯¥æ¡†æ¶å®ç°äº†å®Œæ•´çš„åå‘ä¼ æ’­ç®—æ³•ï¼Œæ”¯æŒæ ‡é‡ã€å‘é‡å’Œå¤šç»´å¼ é‡çš„è‡ªåŠ¨å¾®åˆ†è®¡ç®—ã€‚

> **æ³¨æ„**: æœ¬é¡¹ç›®åŸºäº AI ç”Ÿæˆçš„ä»£ç å¹¶è¿›è¡Œä¿®æ”¹ï¼Œè¯·è°¨æ…ä½¿ç”¨ã€‚

## âœ¨ ä¸»è¦ç‰¹æ€§

### ğŸ§  æ ¸å¿ƒåŠŸèƒ½

- **Variable ç±»**: æ”¯æŒè‡ªåŠ¨å¾®åˆ†çš„æ ¸å¿ƒæ•°æ®ç»“æ„
- **è®¡ç®—å›¾ç®¡ç†**: è‡ªåŠ¨æ„å»ºå’Œç®¡ç†è®¡ç®—å›¾
- **åå‘ä¼ æ’­**: é«˜æ•ˆçš„æ¢¯åº¦è®¡ç®—å’Œä¼ æ’­
- **å†…å­˜ç®¡ç†**: ä½¿ç”¨æ™ºèƒ½æŒ‡é’ˆå’Œ DataView å®ç°é«˜æ•ˆçš„å†…å­˜ç®¡ç†

### ğŸ”§ æ”¯æŒçš„æ“ä½œ

- **åŸºç¡€æ•°å­¦è¿ç®—**: åŠ æ³•ã€å‡æ³•ã€ä¹˜æ³•ã€é™¤æ³•ã€å¹‚è¿ç®—ç­‰
- **æ¿€æ´»å‡½æ•°**: ReLUã€Sigmoidã€Tanhã€Leaky ReLU
- **æŸå¤±å‡½æ•°**: å‡æ–¹è¯¯å·®(MSE)ã€äºŒå…ƒäº¤å‰ç†µ(BCE)
- **å¼ é‡æ“ä½œ**: å·ç§¯ã€æ± åŒ–ã€åˆ‡ç‰‡ã€æ‹¼æ¥ã€å±•å¹³ç­‰
- **å‘é‡è¿ç®—**: æ”¯æŒå‘é‡è¿ç®—å’Œå¹¿æ’­

### ğŸš€ é«˜çº§ç‰¹æ€§

- **å¾ªç¯ç¥ç»ç½‘ç»œ**: æ”¯æŒ RNN å’Œ LSTM ç»“æ„
- **ä¼˜åŒ–å™¨**: Adam ä¼˜åŒ–å™¨
- **å¯è§†åŒ–**: è®¡ç®—å›¾å¯è§†åŒ–åŠŸèƒ½
- **å‚æ•°ä¿å­˜/åŠ è½½**: æ¨¡å‹å‚æ•°çš„æŒä¹…åŒ–
- **Python ç»‘å®š**: é€šè¿‡ cppyy æ”¯æŒ Python è°ƒç”¨

## ğŸ“ é¡¹ç›®ç»“æ„

```{text}
â”œâ”€â”€ autograd.hpp        # ä¸»æ¡†æ¶å¤´æ–‡ä»¶
â”œâ”€â”€ variable.hpp        # Variable ç±»å®šä¹‰
â”œâ”€â”€ operations.hpp      # æ•°å­¦è¿ç®—å®ç°
â”œâ”€â”€ graph.hpp          # è®¡ç®—å›¾ç®¡ç†
â”œâ”€â”€ optimizer.hpp      # ä¼˜åŒ–å™¨å®ç°
â”œâ”€â”€ dataview.hpp       # æ•°æ®è§†å›¾ç±»
â”œâ”€â”€ utils.hpp          # å·¥å…·å‡½æ•°
â”œâ”€â”€ recurrent.hpp      # å¾ªç¯ç¥ç»ç½‘ç»œæ”¯æŒ
â”œâ”€â”€ Makefile           # ç¼–è¯‘è„šæœ¬
â”œâ”€â”€ requirements.txt   # Python ä¾èµ–
â”œâ”€â”€ test/              # æµ‹è¯•å’Œç¤ºä¾‹
â”‚   â”œâ”€â”€ demo.cpp       # åŸºç¡€æ¼”ç¤º
â”‚   â”œâ”€â”€ test.cpp       # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ mnist.cpp      # MNIST æ‰‹å†™æ•°å­—è¯†åˆ«
â”‚   â””â”€â”€ ...            # å…¶ä»–æµ‹è¯•æ–‡ä»¶
â””â”€â”€ docs/              # æ–‡æ¡£ç›®å½•
    â”œâ”€â”€ overview.md    # æ¦‚è¿°æ–‡æ¡£
    â”œâ”€â”€ api/           # API æ–‡æ¡£
    â”œâ”€â”€ examples/      # ç¤ºä¾‹ä»£ç 
    â””â”€â”€ architecture.md # æ¶æ„è®¾è®¡
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¼–è¯‘è¦æ±‚

- C++23 å…¼å®¹çš„ç¼–è¯‘å™¨ (æ¨è GCC 13+ æˆ– Clang 16+)
- Make å·¥å…·
- Python 3.8+ (å¯é€‰ï¼Œç”¨äº Python ç»‘å®š)

### å®‰è£…ä¾èµ–

```bash
# å®‰è£… Python ä¾èµ–ï¼ˆå¯é€‰ï¼‰
pip install -r requirements.txt
```

### ç¼–è¯‘å’Œè¿è¡Œ

```bash
# ç¼–è¯‘æ‰€æœ‰ç¨‹åº
make all

# è¿è¡ŒåŸºç¡€æ¼”ç¤º
make run

# è¿è¡Œæµ‹è¯•ç¨‹åº
make test

# æ¸…ç†ç”Ÿæˆçš„æ–‡ä»¶
make clean

# æŸ¥çœ‹å¸®åŠ©
make help
```

### ç®€å•ç¤ºä¾‹

```cpp
#include "autograd.hpp"

int main() {
    // åˆ›å»ºå˜é‡
    auto x = make_param(2.0);
    auto w = make_param(3.0);
    auto b = make_param(1.0);
    
    // æ„å»ºè®¡ç®—å›¾: y = w * x + b
    auto y = add(mul(w, x), b);
    
    // å‰å‘è®¡ç®—
    y->calc();
    std::cout << "y = " << y->item() << std::endl;  // è¾“å‡º: y = 7
    
    // åå‘ä¼ æ’­
    y->backward();
    std::cout << "dw = " << w->grad_item() << std::endl;  // è¾“å‡º: dw = 2
    std::cout << "dx = " << x->grad_item() << std::endl;  // è¾“å‡º: dx = 3
    
    return 0;
}
```

## ğŸ“š æ–‡æ¡£

- [ğŸ“– æ¦‚è¿°](docs/overview.md) - æ¡†æ¶ä»‹ç»å’Œå¿«é€Ÿå¼€å§‹
- [ğŸ”§ API å‚è€ƒ](docs/api/README.md) - è¯¦ç»†çš„ API æ–‡æ¡£
- [ğŸ’¡ ç¤ºä¾‹](docs/examples/README.md) - å®é™…åº”ç”¨ç¤ºä¾‹
- [ğŸ—ï¸ æ¶æ„è®¾è®¡](docs/architecture.md) - æ¡†æ¶å†…éƒ¨è®¾è®¡è¯´æ˜

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### çº¿æ€§å›å½’

```cpp
// åˆ›å»ºå˜é‡
auto x = make_input(0.0);
auto w = make_param(0.1);
auto b = make_param(0.1);
auto target = make_input(0.0);

// æ„å»ºæ¨¡å‹
auto y_pred = add(mul(w, x), b);
auto loss = mse_loss(y_pred, target);

// è®­ç»ƒå¾ªç¯
for (int epoch = 0; epoch < 100; ++epoch) {
    x->set_input(training_data[epoch]);
    target->set_input(labels[epoch]);
    
    loss->zero_grad_recursive();
    loss->calc();
    loss->backward();
    
    w->update(learning_rate);
    b->update(learning_rate);
}
```

### ç¥ç»ç½‘ç»œ

```cpp
// å¤šå±‚æ„ŸçŸ¥æœº
auto W1 = make_param(vec_r(input_size * hidden_size), {hidden_size, input_size});
auto b1 = make_param(vec_r(hidden_size), {hidden_size});
auto W2 = make_param(vec_r(hidden_size * output_size), {output_size, hidden_size});
auto b2 = make_param(vec_r(output_size), {output_size});

// å‰å‘ä¼ æ’­
auto z1 = add(mul(W1, x, 0, 0), b1);
auto a1 = relu(z1);
auto z2 = add(mul(W2, a1, 0, 0), b2);
auto output = z2;
```

### å·ç§¯ç¥ç»ç½‘ç»œ

```cpp
// å·ç§¯å±‚
auto conv_weights = make_param(vec_r(3 * 3 * 32), {3, 3, 32});
auto conv_out = conv2d(input, conv_weights);
auto relu_out = relu(conv_out);
auto pool_out = MaxPooling(relu_out, 2);
```

### å¾ªç¯ç¥ç»ç½‘ç»œ

```cpp
// LSTM
auto lstm_op = lstm_(hidden_size, hidden_size);
auto lstm = RecurrentOperation(lstm_op, hidden_state, input);
lstm.expand(seq_length);
auto outputs = lstm.outputs;
```

## ğŸ”„ æœ€è¿‘æ›´æ–°

æ ¹æ® git è®°å½•ï¼Œæœ€è¿‘çš„é‡å¤§æ›´æ–°åŒ…æ‹¬ï¼š

- **ğŸ”„ RNN ç½‘ç»œæ”¯æŒ**: æ·»åŠ äº†å¾ªç¯ç¥ç»ç½‘ç»œå’Œ LSTM æ”¯æŒ
- **ğŸ“Š å¯è§†åŒ–åŠŸèƒ½**: æ–°å¢è®¡ç®—å›¾å¯è§†åŒ–åŠŸèƒ½
- **âš¡ Adam ä¼˜åŒ–å™¨**: å®ç°äº† Adam ä¼˜åŒ–ç®—æ³•
- **ğŸ’¾ å‚æ•°ä¿å­˜/åŠ è½½**: æ”¯æŒæ¨¡å‹å‚æ•°çš„æŒä¹…åŒ–
- **ğŸ Python ç»‘å®š**: é€šè¿‡ cppyy æä¾› Python æ¥å£
- **ğŸ”§ é«˜çº§å¼ é‡æ“ä½œ**: å·ç§¯ã€æ± åŒ–ã€åˆ‡ç‰‡ç­‰æ“ä½œ

## ğŸ§ª æµ‹è¯•

é¡¹ç›®åŒ…å«å…¨é¢çš„æµ‹è¯•å¥—ä»¶ï¼š

```bash
# è¿è¡ŒåŸºç¡€æµ‹è¯•
./autograd_test

# è¿è¡Œ MNIST ç¤ºä¾‹
./mnist train

# è¿è¡Œæ¼”ç¤ºç¨‹åº
./autograd_demo
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

### å¼€å‘æŒ‡å—

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ“– å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶æˆ–é¡¹ç›®ä¸­ä½¿ç”¨äº† MyAutoGradï¼Œè¯·è€ƒè™‘å¼•ç”¨æœ¬ä»“åº“ï¼š

```bibtex
@software{myautograd,
  title={MyAutoGrad: C++ Automatic Differentiation Framework},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/myAutoGrad}
}
```

## ğŸ™ è‡´è°¢

- æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…çš„æ”¯æŒ
- çµæ„Ÿæ¥æºäº PyTorchã€TensorFlow ç­‰ä¼˜ç§€æ¡†æ¶
- ç‰¹åˆ«æ„Ÿè°¢å¼€æºç¤¾åŒºçš„æ”¯æŒ

## ğŸ“ è”ç³»æ–¹å¼

- ğŸ“§ Email: [your-email@example.com]
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/myAutoGrad/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/yourusername/myAutoGrad/discussions)

---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª Starï¼
